#　      kafka
## 1、kafka概念
## 2、kafka在系统中的角色
   ![kafka角色](/media/mafenrgui/办公/马锋瑞/spark2/笔记/kafka/kafka扮演的角色.jpeg)
## 3、kafka的应用场景 
### 3.1异步处理
***场景说明***：用户注册后需要发送注册邮件和注册短信传统的做法有两种
    
    串行方式：用户注册信息写入数据库 -> 发送注册短信 -> 发送注册邮箱 -> 返回给客户端
    并行方式：用户注册信息写入数据库 -> 发送注册短信 -> 返回给客户端
                                -> 发送注册邮箱 
    总结：以上是传统系统解决方案，但是随着用户量的增加，系统的性能（并发量、吞吐量、响应时间）都会有瓶颈
**引入消息队列**
    
    用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回
    因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍。  
###3.2应用解耦
***场景说明***：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口
    
    传统模式的缺点：
    1）  假如库存系统无法访问，则订单减库存将失败，从而导致订单失败；
    2）  订单系统与库存系统耦合；
**引入消息队列**
    
    
    订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。
    库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。
    假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。
   

###3.3流量削锋
***场景说明***：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列
**引入消息队列**
    
    
    可以控制活动的人数；
    可以缓解短时间内高流量压垮应用；
    用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面；
    秒杀业务根据消息队列中的请求信息，再做后续处理。
###3.4日志处理
***场景说明***

    每天都有大量日志信息
**引入消息队列&新浪的框架**

    日志采集客户端，负责日志数据采集，定时写受写入Kafka队列；
    Kafka消息队列，负责日志数据的接收，存储和转发；
    日志处理应用：订阅并消费kafka队列中的日志数据；
    以下是新浪kafka日志处理应用案例：
    (1)Kafka：接收用户日志的消息队列。
    (2)Logstash：做日志解析，统一成JSON输出给Elasticsearch。
    (3)Elasticsearch：实时日志分析服务的核心技术，一个schemaless，实时的数据存储服务，通过index组织数据，兼具强大的搜索和统计功能。
    (4)Kibana：基于Elasticsearch的数据可视化组件，超强的数据可视化能力是众多公司选择ELK stack的重要原因。   
###3.5消息通信
***场景说明&引入消息队列***
    
    点对点：A与B使用同一消息队列进行通信
    聊天室(订阅发布):客户端A，客户端B，......客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。
##kafka的架构
 ![架构](/media/mafenrgui/办公/马锋瑞/spark2/笔记/kafka/kafka架构.jpeg)

    每当一个message被发布到一个topic上的partition,broker应会将message追加到这个`逻辑`log文件的最后一个segment上，这些segments会被flush到磁盘上。flush时可以按照时间来进行也可以按照message数来执行。
    每个parttion会有一个有序的、不可变的结构化的提交日志记录的序列。
    在每个partition上每一条日志记录都会被分配一个序号-------通常被称为offset，offset在每个partition内是唯一的。论点逻辑文件会被分化为多个文件的segment（每个segment的大小一样的）
###问题1 kafka如何进行partition、replica 分配的？
#### Kafka Topic 的创建方式
          1、创建topic时直接指定Topic Partition Replica与Kafka Broker的依赖关系
           2、创建Topic时由Kafka自动分配Topic Partition Replica与Kafka Broker之间的存储映射关系
   http://www.cnblogs.com/yurunmiao/p/5550906.html
#### Kafka Topic Partition Replica Assignment实现原理

###问题1 kafka为什么采用拉去模式
    
    消费者与生产者没有关系，当生产者生产力强的时候，全部推给消费者时候，会造成阻塞
    所以采取消费者拉去数据的模式

###问题1 怎么实现单播与广播
    消费者的放置，广播放在不同组，单播同一组

https://www.cnblogs.com/seaspring/p/6138080.html
###问题1 怎么计算分区个数
    
     
        
        
        
##kafka在zookeeper上的节点信息和查看方式

    zookeeper的作用：
        集群管理，负载均衡
    
https://blog.csdn.net/qq_36838191/article/details/80553637
https://blog.csdn.net/lizhitao/article/details/23744675                     


